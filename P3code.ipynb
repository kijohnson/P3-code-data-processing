{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c88af47-c057-406a-ae47-5c96f0d6595c",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ead53217-64b7-4aec-989f-4124d76308e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import datetime64\n",
    "import warnings\n",
    "from datetime import timedelta\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "144c66b2-3dc2-4179-8051-c7acb407a634",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2805b258-9a0e-4ab2-a3a5-8e3a1f96b08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kim's working directory\n",
    "os.chdir('/Users/kimjohnson/Library/CloudStorage/Box-Box/03_MisinformationMon/Data Team/Data management and analysis/Data inputs and outputs/')\n",
    "\n",
    "# Olivia's working ddirectory\n",
    "# os.chdir('/Users/OW/Box/03_MisinformationMon/Data Team/Data management and analysis/Data inputs and outputs/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e8b5ba-4d28-458c-99e6-5dc456cd58e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f6a5286e-d889-4797-b723-80a756fe6c51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survey_var</th>\n",
       "      <th>result_var</th>\n",
       "      <th>inaccurate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M1_VaxFail</td>\n",
       "      <td>VaxFail</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M10_KidMild</td>\n",
       "      <td>KidMild</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M11_KidSafe</td>\n",
       "      <td>KidSafe</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M12_Booster</td>\n",
       "      <td>Booster</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M13_CovPill</td>\n",
       "      <td>CovPill</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    survey_var result_var inaccurate\n",
       "0   M1_VaxFail    VaxFail        Yes\n",
       "1  M10_KidMild    KidMild        Yes\n",
       "2  M11_KidSafe    KidSafe        Yes\n",
       "3  M12_Booster    Booster        Yes\n",
       "4  M13_CovPill    CovPill        Yes"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('3_GENERATED WEEKLY FILES/SurveyExport_Merged.xlsx')\n",
    "\n",
    "myth_vars = pd.read_csv('2_DATA_PROCESSING/myth_vars.csv')\n",
    "\n",
    "unique_myths = myth_vars.survey_var.unique() # gets list of unique myths thesee all have numbers though\n",
    "myth_vars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5019fb81-5074-4a26-9fe9-d19ed8ae6fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIassess = df[[\"ExternalReference\", \"M_more\", \"surveydate\", \"M_more_react\", \"site\"]].dropna()\n",
    "pd.DataFrame(MIassess).to_excel('3_GENERATED WEEKLY FILES/MIassess.xlsx', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "46d1e8d1-9aa3-4755-8a1f-2cf08baeccf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "better = df[[\"ExternalReference\", \"STL_Better\", \"surveydate\", \"site\"]].dropna()\n",
    "STL_better = (better[(better['site'] == 'STL')])\n",
    "CO_better = (better[(better['site'] == 'CO')])\n",
    "NE_better = (better[(better['site'] == 'NE')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c2bb6bd8-e011-4e0c-9180-788f6b4abf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(better).to_excel('3_GENERATED WEEKLY FILES/better.xlsx', header=True, index=False)\n",
    "pd.DataFrame(STL_better).to_excel('3_GENERATED WEEKLY FILES/STL_better.xlsx', header=True, index=False)\n",
    "pd.DataFrame(CO_better).to_excel('3_GENERATED WEEKLY FILES/CO_better.xlsx', header=True, index=False)\n",
    "pd.DataFrame(NE_better).to_excel('3_GENERATED WEEKLY FILES/NE_better.xlsx', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d6dad7c1-49e9-4bc8-a221-409083587f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "inaccurate = (myth_vars[(myth_vars['inaccurate'] == 'Yes')]).survey_var.unique()\n",
    "accurate = (myth_vars[(myth_vars['inaccurate'] == 'No')]).survey_var.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "852587d7-06e2-4007-8cb6-8c808252c6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_sites = pd.unique(df['site'])\n",
    "unique_sources = ['On social media', 'Other internet source', 'TV/radio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "48a91295-e8f9-4497-bf57-bc3ec9fbfc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "result.append(['myth', 'survey_date', 'group', 'exposure', 'believe'])\n",
    "print(type(result))\n",
    "\n",
    "source_result = []\n",
    "source_result.append(['myth', 'survey_date', 'source_pct', 'source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8cec0c80-391e-4f86-a19d-7a5b45fce4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accurate = df[['surveydate', 'site']]\n",
    "df_inaccurate = df[['surveydate', 'site']]\n",
    "\n",
    "any_heard_result = []\n",
    "any_heard_result.append(['surveydate', 'sum_inac', 'count_inac', 'inaccurate_pct', 'sum_acc', 'count_acc', 'accurate_pct', 'source'])\n",
    "# In[25]:\n",
    "\n",
    "#Create seperate dataframes for accurate and inaccurate myths\n",
    "for each_myth in unique_myths:\n",
    "    df_extracted = df[[each_myth]]\n",
    "    if (each_myth in accurate):\n",
    "        df_accurate = pd.concat([df_accurate, df_extracted], axis=1)\n",
    "\n",
    "    if (each_myth in inaccurate):\n",
    "        df_inaccurate = pd.concat([df_inaccurate, df_extracted], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9c9890cb-e892-4edd-bdb8-7cb44a7687f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def any_heard(each_date, each_site):\n",
    "    if(each_site == 'All'):\n",
    "        acc_for_date = df_accurate.loc[df_accurate['surveydate'] == each_date]\n",
    "        inacc_for_date = df_inaccurate.loc[df_inaccurate['surveydate'] == each_date]\n",
    "        length_total = acc_for_date.shape[0]\n",
    "\n",
    "        temp_acc = acc_for_date.iloc[:, 2:]\n",
    "        temp_acc = temp_acc[(temp_acc == 'Yes').any(axis=1)]\n",
    "        length_of_temp_acc = len(temp_acc[(temp_acc == 'Yes').any(axis=1)])\n",
    "\n",
    "        temp_inacc = inacc_for_date.iloc[:, 2:]\n",
    "        temp_inacc = temp_inacc[(temp_inacc == 'Yes').any(axis=1)]\n",
    "        length_of_temp_inacc = len(temp_inacc[(temp_inacc == 'Yes').any(axis=1)])\n",
    "\n",
    "        if(length_total > 0):\n",
    "            row_to_input = [each_date, length_of_temp_inacc, length_total, round((length_of_temp_inacc / length_total), 2), length_of_temp_acc, length_total, round((length_of_temp_acc / length_total), 2), 'All']\n",
    "        else:\n",
    "            row_to_input = [each_date, length_of_temp_inacc, length_total, 0, length_of_temp_acc, length_total, 0, 'All']\n",
    "        any_heard_result.append(row_to_input)\n",
    "\n",
    "    elif (each_site != 'All'):\n",
    "        acc_for_date = df_accurate[(df_accurate['surveydate'] == each_date) & (df_accurate['site'] == each_site)]\n",
    "        inacc_for_date = df_inaccurate.loc[df_inaccurate['surveydate'] == each_date]\n",
    "        length_total = acc_for_date.shape[0]\n",
    "\n",
    "        temp_acc = acc_for_date.iloc[:, 2:]\n",
    "        temp_acc = temp_acc[(temp_acc == 'Yes').any(axis=1)]\n",
    "        length_of_temp_acc = len(temp_acc[(temp_acc == 'Yes').any(axis=1)])\n",
    "\n",
    "        temp_inacc = inacc_for_date.iloc[:, 2:]\n",
    "        temp_inacc = temp_inacc[(temp_inacc == 'Yes').any(axis=1)]\n",
    "        length_of_temp_inacc = len(temp_inacc[(temp_inacc == 'Yes').any(axis=1)])\n",
    "\n",
    "        if(length_total >  0):\n",
    "            row_to_input = [each_date, length_of_temp_inacc, length_total, round((length_of_temp_inacc / length_total), 2), length_of_temp_acc, length_total, round((length_of_temp_acc / length_total), 2), each_site]\n",
    "\n",
    "        else:\n",
    "            row_to_input = [each_date, length_of_temp_inacc, length_total, 0, length_of_temp_acc, length_total, 0, 'All']\n",
    "        any_heard_result.append(row_to_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c782acd7-8274-43a3-bbcd-0e42eea702d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def source_calculation(source_result, unique_sources, date_column, each_myth, each_site):\n",
    "    if (each_site != 'All'):\n",
    "        source_total = len(df_source[(df_source[each_myth] == 'Yes') & (df_source['site'] == each_site) & (df_source['surveydate'] == date_column)])\n",
    "        source_said_yes_max = len(df_source[(df_source[each_myth + '_where'].str.contains('Family member or friend|Neighbor or coworker|Someone else')) &\n",
    "                                            (df_source['site'] == each_site) &\n",
    "                                            (df_source['surveydate'] == date_column)])\n",
    "        each_source_max = 'Family friend or someone else'\n",
    "        for each_source in unique_sources:\n",
    "            source_said_yes = len(df_source[(df_source[each_myth + '_where'].str.contains(each_source)) & (df_source['site'] == each_site) & (df_source['surveydate'] == date_column)])\n",
    "            if (source_said_yes > source_said_yes_max):\n",
    "                source_said_yes_max = source_said_yes\n",
    "                each_source_max = each_source\n",
    "            elif ((source_said_yes == source_said_yes_max) and (each_source == 'TV/Radio' or each_source == 'Other internet source')):\n",
    "                source_said_yes_max = source_said_yes\n",
    "                each_source_max = each_source\n",
    "        if (source_said_yes_max > 0 and source_total > 0):\n",
    "            row_to_input = [each_myth, date_column, round((source_said_yes_max / source_total) * 100, 1), each_source_max, each_site]\n",
    "            source_result.append(row_to_input)\n",
    "    elif(each_site == 'All'):\n",
    "        source_total = len(df_source[(df_source[each_myth] == 'Yes') & (df_source['surveydate'] == date_column)])\n",
    "        source_said_yes_max = len(df_source[(df_source[each_myth + '_where'].str.contains('Family member or friend|Neighbor or coworker|Someone else')) &\n",
    "                                            (df_source['surveydate'] == date_column)])\n",
    "        each_source_max = 'Family friend or someone else'\n",
    "        for each_source in unique_sources:\n",
    "            source_said_yes = len(df_source[(df_source[each_myth + '_where'].str.contains(each_source)) & (df_source['surveydate'] == date_column)])\n",
    "            if (source_said_yes > source_said_yes_max):\n",
    "                source_said_yes_max = source_said_yes\n",
    "                each_source_max = each_source\n",
    "            elif ((source_said_yes == source_said_yes_max) and (each_source == 'TV/Radio' or each_source == 'Other internet source')):\n",
    "                source_said_yes_max = source_said_yes\n",
    "                each_source_max = each_source\n",
    "        if (source_said_yes_max > 0 and source_total > 0):\n",
    "            row_to_input = [each_myth, date_column, round((source_said_yes_max / source_total) * 100, 1), each_source_max, 'All']\n",
    "            source_result.append(row_to_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "21ee0597-1ce8-4869-a0d4-a9662f4ae437",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_results(result, unique_column, column_name, date_column, each_myth, each_site):\n",
    "    if (each_site != 'All' and column_name  != 'All'):\n",
    "        for each_value in unique_column:\n",
    "            myth_total = len(df1[(df1[column_name] == each_value) & (df1['site'] == each_site) & (df1['surveydate'] == date_column)])\n",
    "            myth_yes = len(df1[(df1[column_name] == each_value) & (df1['site'] == each_site) & (df1['surveydate'] == date_column) & (df1[each_myth] == 'Yes')])\n",
    "\n",
    "            df_believe_not_null['sub_rank'] = df_believe_not_null.groupby('ExternalReference')['surveydate'].rank(method='dense', ascending=True)\n",
    "            df3 = df_believe_not_null.loc[df_believe_not_null['surveydate'] <= date_column]\n",
    "\n",
    "            believe_total = len(df3[(df3['sub_rank'] == 1) & (df3[column_name] == each_value) & (df3['site'] == each_site)])\n",
    "            believe_first = len(df3[(df3['sub_rank'] == 1) & (df3[each_myth + '_react'] == 1) & (df3[column_name] == each_value) & (df3['site'] == each_site)])\n",
    "\n",
    "            if (believe_total != 0 and myth_total != 0):\n",
    "                single_all_row = [each_myth, date_column, each_value, round((myth_yes / myth_total) * 100, 1),round((believe_first / believe_total) * 100, 1), each_site]\n",
    "                result.append(single_all_row)\n",
    "            \n",
    "            elif (believe_total == 0 and myth_total != 0):\n",
    "                single_all_row = [each_myth, date_column, each_value, 0, 0, each_site]\n",
    "                result.append(single_all_row)\n",
    "\n",
    "    elif(each_site == 'All' and column_name != 'All'):\n",
    "        for each_value in unique_column:\n",
    "            myth_total = len(df1[(df1[column_name] == each_value) & (df1['surveydate'] == date_column)])\n",
    "            myth_yes = len(df1[(df1[column_name] == each_value) & (df1['surveydate'] == date_column) & (df1[each_myth] == 'Yes')])\n",
    "\n",
    "            df_believe_not_null['sub_rank'] = df_believe_not_null.groupby('ExternalReference')['surveydate'].rank(method='dense', ascending=True)\n",
    "            df3 = df_believe_not_null.loc[df_believe_not_null['surveydate'] <= date_column]\n",
    "\n",
    "            believe_total = len(df3[(df3['sub_rank'] == 1) & (df3[column_name] == each_value)])\n",
    "            believe_first = len(df3[(df3['sub_rank'] == 1) & (df3[each_myth + '_react'] == 1) & (df3[column_name] == each_value)])\n",
    "\n",
    "            if (believe_total != 0 and myth_total != 0):\n",
    "                single_all_row = [each_myth, date_column, each_value, round((myth_yes / myth_total) * 100, 1),round((believe_first / believe_total) * 100, 1), 'All']\n",
    "                result.append(single_all_row)\n",
    "                \n",
    "            elif (believe_total == 0 and myth_total != 0):\n",
    "                single_all_row = [each_myth, date_column, each_value, 0, 0, each_site]\n",
    "                result.append(single_all_row)\n",
    "\n",
    "    elif (each_site != 'All' and column_name == 'All'):\n",
    "        myth_total = len(df1[(df1['site'] == each_site) & (df1['surveydate'] == date_column)])\n",
    "        myth_yes = len(df1[(df1['site'] == each_site) & (df1['surveydate'] == date_column) & (df1[each_myth] == 'Yes')])\n",
    "\n",
    "        df_believe_not_null['sub_rank'] = df_believe_not_null.groupby('ExternalReference')['surveydate'].rank(method='dense', ascending=True)\n",
    "        df3 = df_believe_not_null.loc[df_believe_not_null['surveydate'] <= date_column]\n",
    "\n",
    "        believe_total = len(df3[(df3['sub_rank'] == 1) & (df3['site'] == each_site)])\n",
    "        believe_first = len(df3[(df3['sub_rank'] == 1) & (df3[each_myth + '_react'] == 1) & (df3['site'] == each_site)])\n",
    "\n",
    "        if (believe_total != 0 and myth_total != 0):\n",
    "            single_all_row = [each_myth, date_column, 'All', round((myth_yes / myth_total) * 100, 1),round((believe_first / believe_total) * 100, 1), each_site]\n",
    "            result.append(single_all_row)\n",
    "            \n",
    "        elif (believe_total == 0 and myth_total != 0):\n",
    "            single_all_row = [each_myth, date_column, 'All', 0, 0, each_site]\n",
    "            result.append(single_all_row)\n",
    "\n",
    "    elif (each_site == 'All' and column_name == 'All'):\n",
    "        myth_total = len(df1[(df1['surveydate'] == date_column)])\n",
    "        myth_yes = len(df1[(df1['surveydate'] == date_column) & (df1[each_myth] == 'Yes')])\n",
    "\n",
    "        df_believe_not_null['sub_rank'] = df_believe_not_null.groupby('ExternalReference')['surveydate'].rank(method='dense', ascending=True)\n",
    "        df3 = df_believe_not_null.loc[df_believe_not_null['surveydate'] <= date_column]\n",
    "\n",
    "        believe_total = len(df3[(df3['sub_rank'] == 1)])\n",
    "        believe_first = len(df3[(df3['sub_rank'] == 1) & (df3[each_myth + '_react'] == 1)])\n",
    "\n",
    "        if (believe_total != 0 and myth_total != 0):\n",
    "            single_all_row = [each_myth, date_column, 'All', round((myth_yes / myth_total) * 100, 1), round((believe_first / believe_total) * 100, 1), 'All']\n",
    "            result.append(single_all_row)\n",
    "            \n",
    "        elif (believe_total == 0 and myth_total != 0):\n",
    "            single_all_row = [each_myth, date_column, 'All', 0, 0, each_site]\n",
    "            result.append(single_all_row)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeae0bc1-c20c-4516-8efa-9b38be326c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for each_myth in unique_myths:\n",
    "    if each_myth in df:\n",
    "        df1 = df[[each_myth, 'age_cat_current', 'gender_cat', 'race_cat', 'partype', 'surveydate', 'site']].dropna()\n",
    "        unique_survey_dates = df1.surveydate.unique()\n",
    "        unique_race = df1.race_cat.unique()\n",
    "        unique_gender = df1.gender_cat.unique()\n",
    "        unique_age_current= df1.age_cat_current.unique()\n",
    "        unique_partype = df1.partype.unique()\n",
    "\n",
    "        df_believe = df[[each_myth, each_myth + '_react', 'age_cat_current', 'gender_cat', 'race_cat', 'partype', 'surveydate', 'ExternalReference', 'site']].dropna()\n",
    "\n",
    "        df_source = df[[each_myth, each_myth + '_where', 'surveydate', 'site']].dropna()\n",
    "        unique_sources = df_source[each_myth + '_where'].unique()\n",
    "\n",
    "    #############################################################################\n",
    "    # new code to calculate sources information:\n",
    "    # if each_myth in df.columns:\n",
    "\n",
    "\n",
    "        if each_myth in inaccurate:\n",
    "            df_believe[each_myth + '_react'] = df_believe[each_myth + '_react'].replace(['Seems like it could be true'], 1)\n",
    "            df_believe[each_myth + '_react'] = df_believe[each_myth + '_react'].replace(['Definitely true'], 1)\n",
    "            df_believe[each_myth + '_react'] = df_believe[each_myth + '_react'].replace(['Not sure if it\\'s true or untrue'], 1)\n",
    "            df_believe[each_myth + '_react'] = df_believe[each_myth + '_react'].replace(['Definitely not true'], 0)\n",
    "            df_believe[each_myth + '_react'] = df_believe[each_myth + '_react'].replace(['Seems like it\\'s not true'], 0)\n",
    "\n",
    "        if each_myth in accurate:\n",
    "            df_believe[each_myth + '_react'] = df_believe[each_myth + '_react'].replace(['Seems like it could be true'], 1)\n",
    "            df_believe[each_myth + '_react'] = df_believe[each_myth + '_react'].replace(['Definitely true'], 1)\n",
    "            df_believe[each_myth + '_react'] = df_believe[each_myth + '_react'].replace(['Not sure if it\\'s true or untrue'], 0)\n",
    "            df_believe[each_myth + '_react'] = df_believe[each_myth + '_react'].replace(['Definitely not true'], 0)\n",
    "            df_believe[each_myth + '_react'] = df_believe[each_myth + '_react'].replace(['Seems like it\\'s not true'], 0)\n",
    "\n",
    "        df_believe['sub_rank'] = df_believe.groupby('ExternalReference')['surveydate'].rank(method='dense', ascending=True)\n",
    "        df_believe = df_believe.astype({'surveydate': datetime64})\n",
    "\n",
    "        df_believe_not_null = df_believe.loc[df_believe[each_myth].notnull()]\n",
    "\n",
    "        for date_column in unique_survey_dates:\n",
    "            # For each race\n",
    "            unique_column = unique_race\n",
    "            column_name = 'race_cat'\n",
    "            for each_site in unique_sites:\n",
    "                populate_results(result, unique_column, column_name, date_column, each_myth, each_site)\n",
    "\n",
    "            # For each gender\n",
    "            unique_column = unique_gender\n",
    "            column_name = 'gender_cat'\n",
    "            for each_site in unique_sites:\n",
    "                populate_results(result, unique_column, column_name, date_column, each_myth, each_site)\n",
    "            \n",
    "            # For each age current\n",
    "            unique_column = unique_age_current\n",
    "            column_name = 'age_cat_current'\n",
    "            for each_site in unique_sites:\n",
    "                populate_results(result, unique_column, column_name, date_column, each_myth, each_site)\n",
    "\n",
    "           # For each partype\n",
    "            unique_column = unique_partype\n",
    "            column_name = 'partype'\n",
    "            for each_site in unique_sites:\n",
    "                populate_results(result, unique_column, column_name, date_column, each_myth, each_site)\n",
    "\n",
    "            for each_site in unique_sites:\n",
    "                populate_results(result, 'All', 'All', date_column, each_myth, each_site)\n",
    "                source_calculation(source_result, unique_sources, date_column, each_myth, each_site)\n",
    "                any_heard(date_column, each_site)\n",
    "                \n",
    "            populate_results(result, 'All', 'All', date_column, each_myth, 'All')\n",
    "            source_calculation(source_result, unique_sources, date_column, each_myth, 'All')\n",
    "            any_heard(date_column, 'All')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c408b4e4-a850-45f6-8a99-8c68de64fafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename myth variable in myth_vars to myth for merging\n",
    "myth_vars2 = myth_vars.rename(columns={\"survey_var\": \"myth\"})\n",
    "\n",
    "# drop result_var\n",
    "myth_vars2 = myth_vars2.drop(columns = ['result_var'])\n",
    "myth_vars2.rename(columns=myth_vars2.iloc[1])\n",
    "myth_vars2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00bb5e1-8512-4147-a507-83274cc64245",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(result)\n",
    "new_header = result.iloc[0] # grab the first row for the header\n",
    "result = result[1:] # take the data less the header row\n",
    "result.columns = new_header # set the header row as the df header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f69b7b8-ee7b-446f-8518-6803b3d27a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66412a4-d745-48e0-bf4e-0d9019f62af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge in accuracy of myth variable\n",
    "results = pd.merge(result, myth_vars2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785925fe-e4f4-45e2-bab4-ae89f7c657ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedab62f-b632-426d-965b-bbfe19df6665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code threat levels\n",
    "results['risk'] = 100 *(results.exposure * results.believe/(100*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08bb1cb-7728-4ea9-8445-ba56ae75b511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the inverse for accurate information items\n",
    "results.risk = np.where(results.inaccurate == 'Yes', results.risk, results.risk *  -1) # np.where is like ifelse\n",
    "results.sort_values(by=['risk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f02ef4-b179-4b86-97df-308cfb02bb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ebe662-f9d2-4346-a006-862956b9d472",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['risk_level'] = np.where(results.inaccurate == \"Yes\",\n",
    "                                 pd.cut(results.risk, [0, 5, 20, 100], \n",
    "                                        labels=(\"low\", \"moderate\", \"high\"),\n",
    "                                        include_lowest=True),\n",
    "                                 pd.cut(results.risk, [-100, -20, -5, 0], \n",
    "                                        labels=(\"low\", \"moderate\", \"high\"), \n",
    "                                        include_lowest=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ede6a89-db65-4839-a1a9-20c4c3f40ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f15b134-dbc6-4be0-b6ee-734b21185cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['survey_date']= pd.to_datetime(results['survey_date']) # convert the 'surveydate' column to date format\n",
    "results.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09558d5-dd6a-444b-8969-5b5b9b982e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge in myth name and drop myth column or strip everything including _ before name\n",
    "results['myth'] = results['myth'].str.replace('..+?\\_', '', 1, regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8e7c87-52c9-45c9-b260-043be57a9cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name site column site\n",
    "results.rename(columns={None:'site'}, inplace=True) #Note: None is a system column name with no single quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07392b76-54c7-426b-bc48-7701a92db1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.tail()\n",
    "list(results.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea39eb7-6ffd-46b7-9ba6-c996ee7b958a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change date format and get site specific files\n",
    "results['survey_date'] = pd.to_datetime(results['survey_date']).dt.date\n",
    "STL_results = (results[(results['site'] == 'STL')])\n",
    "CO_results = (results[(results['site'] == 'CO')])\n",
    "NE_results = (results[(results['site'] == 'NE')])\n",
    "\n",
    "# export site specific files\n",
    "pd.DataFrame(results).to_csv('3_GENERATED WEEKLY FILES/M_all2.csv', index = False)\n",
    "pd.DataFrame(STL_results).to_csv('3_GENERATED WEEKLY FILES/STL_M_all2.csv', index = False)\n",
    "pd.DataFrame(CO_results).to_csv('3_GENERATED WEEKLY FILES/CO_M_all2.csv', index = False)\n",
    "pd.DataFrame(NE_results).to_csv('3_GENERATED WEEKLY FILES/NE_M_all2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5a7a0b-dd69-4e46-92bc-89dd424a335d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.head()\n",
    "CO_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ae3aa0-d74a-4585-81ea-f29c16bdf6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify retiring items for ALL sites\n",
    "# (exposure declining for 3 consecutive weeks and the most recent week <15%)\n",
    "flag = results.loc[(results['survey_date'] > (results['survey_date'].max()-timedelta(days=20))) & (results['site'] == 'All')]\n",
    "flag = flag.pivot(index = \"myth\", columns = \"survey_date\", values = \"exposure\").dropna()\n",
    "flag = flag.loc[(flag[flag.columns[-1]] < 15)]\n",
    "flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64440604-f6f5-48e8-b786-7d7700c79bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(flag.index.values)\n",
    "for i in a:\n",
    "    flag_each_site = results.loc[(results['survey_date'] > (results['survey_date'].max()-timedelta(days=20))) & (results['myth'] == i) & (results['group'] == 'All') & (results['site'] != 'All')]\n",
    "    flag_each_site = flag_each_site[['myth', 'survey_date', 'site', 'exposure']]\n",
    "    #flag_each_site = flag_each_site.pivot(index = \"myth\", columns = \"survey_date\", values = \"exposure\").dropna()\n",
    "    print(flag_each_site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b504bb43-11b1-4012-95cc-84f25d4d9093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify retiring items for STL\n",
    "# (exposure declining for 3 consecutive weeks and the most recent week <15%)\n",
    "flag_STL = STL_results.loc[(STL_results['survey_date'] > (STL_results['survey_date'].max()-timedelta(days=20))) & (STL_results['group'] == 'All')]\n",
    "flag_STL = flag_STL.pivot(index = \"myth\", columns = \"survey_date\", values = \"exposure\").dropna()\n",
    "flag_STL = flag_STL.loc[(flag_STL[flag_STL.columns[-1]] < 15)]\n",
    "flag_STL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06054b5c-0ea6-4de1-afc5-16b13dce2a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify retiring items for CO\n",
    "# (exposure declining for 3 consecutive weeks and the most recent week <15%)\n",
    "flag_CO = CO_results.loc[(CO_results['survey_date'] > (CO_results['survey_date'].max()-timedelta(days=20))) & (CO_results['group'] == 'All')]\n",
    "flag_CO = flag_CO.pivot(index = \"myth\", columns = \"survey_date\", values = \"exposure\").dropna()\n",
    "flag_CO = flag_CO.loc[(flag_CO[flag_CO.columns[-1]] < 15)]\n",
    "flag_CO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03db9e04-22f1-4584-b2ce-e6227801a24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify retiring items for NE\n",
    "# (exposure declining for 3 consecutive weeks and the most recent week <15%)\n",
    "flag_NE = NE_results.loc[(NE_results['survey_date'] > (NE_results['survey_date'].max()-timedelta(days=20))) & (NE_results['group'] == 'All')]\n",
    "flag_NE = flag_NE.pivot(index = \"myth\", columns = \"survey_date\", values = \"exposure\").dropna()\n",
    "flag_NE = flag_NE.loc[(flag_NE[flag_NE.columns[-1]] < 15)]\n",
    "flag_NE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013840f0-ba75-4aff-b3cd-829943d6ff00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# longitudinal analysis for PreventionFreq\n",
    "prevent = df.loc[df['surveydate'] >= \"2023-02-18\"]\n",
    "a = prevent['PreventionFreq'].groupby(prevent['surveydate']).value_counts(normalize=True).reset_index(name='percent')\n",
    "a = pd.DataFrame(a)\n",
    "a.columns = [\"surveydate\", \"response\", \"percentage\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9a3ed4-fd59-4a1e-858b-c9a7e7e0ed6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "p = sns.lineplot(x='surveydate', y='percentage', hue='response', data=a, marker=\"o\")\n",
    "p.set_xticks(a['surveydate'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb0da0f-3fc8-4d3c-9052-4fab92c2d001",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_result = pd.DataFrame(source_result)\n",
    "source_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2d47a7-b557-48d7-95b9-aaf0419760b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change first row to header row\n",
    "source_result = pd.DataFrame (source_result)\n",
    "header_row = 0\n",
    "source_result.columns = source_result.iloc[header_row]\n",
    "source_result = source_result.drop(source_result.index[[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85a8c03-005e-4213-9774-b483600497bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4f06c5-985f-499a-9df3-dfae9c7453eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['date'] = pd.to_datetime(df['date']).dt.date\n",
    "source_result['survey_date'] = pd.to_datetime(source_result['survey_date']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61be8655-25cc-4f23-88a2-7496a279853d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name site column site\n",
    "source_result.rename(columns={None:'site'}, inplace=True) # Note: None is a system column name with no single quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc03b928-c0c7-43e6-b8d2-cfc2f5e5a1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0016f353-099a-4472-9b3a-32f7db19de51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip everything including _ before name\n",
    "source_result['myth'] = source_result['myth'].str.replace('..+?\\_', '', 1, regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82db5fea-6b9a-4179-9889-bb10ed3d9989",
   "metadata": {},
   "outputs": [],
   "source": [
    "STL_source_result = (source_result[(source_result['site'] == 'STL')])\n",
    "CO_source_result = (source_result[(source_result['site'] == 'CO')])\n",
    "NE_source_result = (source_result[(source_result['site'] == 'NE')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8163bcbf-d02a-4de7-b1b9-466edd6efd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(source_result).to_csv('3_GENERATED WEEKLY FILES/Top_Sources.csv', header=True, index=False)\n",
    "pd.DataFrame(STL_source_result).to_csv('3_GENERATED WEEKLY FILES/STL_Top_Sources.csv', header=True, index=False)\n",
    "pd.DataFrame(CO_source_result).to_csv('3_GENERATED WEEKLY FILES/CO_Top_Sources.csv', header=True, index=False)\n",
    "pd.DataFrame(NE_source_result).to_csv('3_GENERATED WEEKLY FILES/NE_Top_Sources.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c97cfe-3d1c-4156-a6f0-29417da00c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(any_heard_result).to_csv('3_GENERATED WEEKLY FILES/any_heard.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
